{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "71d08210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from surprise import Reader, Dataset, KNNBasic, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b561c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/FINAL-RATINGS.csv')\n",
    "books = pd.read_csv('data/FINAL-BOOKS-WITH-TAGS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "24f5acfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1185991, 3), (10000, 9))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape, books.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc372c",
   "metadata": {},
   "source": [
    "## Baseline model (popularity-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eac99f",
   "metadata": {},
   "source": [
    "* **Purpose:** To establish a very simple benchmark. This model recommends the same most popular books to *every* user, regardless of their individual preferences.\n",
    "\n",
    "* **Metrics Definition:** Explains the ranking metrics used throughout the notebook:\n",
    "\n",
    "    * `Precision@K`: Out of the K books recommended, what fraction did the user actually rate highly (often defined as rating >= threshold like 4.0) in the hidden test set?\n",
    "\n",
    "    * `Recall@K`: Out of all the books the user rated highly in the hidden test set, what fraction were captured within the top K recommendations?\n",
    "    \n",
    "    * `Hit Rate@K`: Did *at least one* of the user's highly-rated test set books appear in the top K recommendations? (Binary: 1 if yes, 0 if no, then averaged over users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1401a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64ffebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute book popularity (rating counts)\n",
    "popularity = (\n",
    "    train_df['book_id']\n",
    "    .value_counts()\n",
    "    .reset_index(name='count')\n",
    "    .rename(columns={'index':'book_id'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c62740a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Popular Books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "average_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "50315cb1-2264-4183-a9f6-7a68a3dbc5d7",
       "rows": [
        [
         "0",
         "1",
         "The Hunger Games (The Hunger Games, #1)",
         "4.34",
         "3632"
        ],
        [
         "1",
         "2",
         "Harry Potter and the Sorcerer's Stone (Harry Potter, #1)",
         "4.44",
         "3487"
        ],
        [
         "2",
         "4",
         "To Kill a Mockingbird",
         "4.25",
         "3094"
        ],
        [
         "3",
         "3",
         "Twilight (Twilight, #1)",
         "3.57",
         "2690"
        ],
        [
         "4",
         "5",
         "The Great Gatsby",
         "3.89",
         "2596"
        ],
        [
         "5",
         "17",
         "Catching Fire (The Hunger Games, #2)",
         "4.3",
         "2587"
        ],
        [
         "6",
         "20",
         "Mockingjay (The Hunger Games, #3)",
         "4.03",
         "2587"
        ],
        [
         "7",
         "18",
         "Harry Potter and the Prisoner of Azkaban (Harry Potter, #3)",
         "4.53",
         "2547"
        ],
        [
         "8",
         "23",
         "Harry Potter and the Chamber of Secrets (Harry Potter, #2)",
         "4.37",
         "2485"
        ],
        [
         "9",
         "24",
         "Harry Potter and the Goblet of Fire (Harry Potter, #4)",
         "4.53",
         "2470"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>4.44</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>Catching Fire (The Hunger Games, #2)</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>Mockingjay (The Hunger Games, #3)</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Harr...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Harry...</td>\n",
       "      <td>4.37</td>\n",
       "      <td>2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (Harry Pot...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>2470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title  average_rating  \\\n",
       "0        1            The Hunger Games (The Hunger Games, #1)            4.34   \n",
       "1        2  Harry Potter and the Sorcerer's Stone (Harry P...            4.44   \n",
       "2        4                              To Kill a Mockingbird            4.25   \n",
       "3        3                            Twilight (Twilight, #1)            3.57   \n",
       "4        5                                   The Great Gatsby            3.89   \n",
       "5       17               Catching Fire (The Hunger Games, #2)            4.30   \n",
       "6       20                  Mockingjay (The Hunger Games, #3)            4.03   \n",
       "7       18  Harry Potter and the Prisoner of Azkaban (Harr...            4.53   \n",
       "8       23  Harry Potter and the Chamber of Secrets (Harry...            4.37   \n",
       "9       24  Harry Potter and the Goblet of Fire (Harry Pot...            4.53   \n",
       "\n",
       "   count  \n",
       "0   3632  \n",
       "1   3487  \n",
       "2   3094  \n",
       "3   2690  \n",
       "4   2596  \n",
       "5   2587  \n",
       "6   2587  \n",
       "7   2547  \n",
       "8   2485  \n",
       "9   2470  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top‑N popular books\n",
    "N = 10\n",
    "\n",
    "top_popular = (\n",
    "    popularity\n",
    "    .head(N)\n",
    "    .merge(books[['book_id','title','average_rating']],\n",
    "           on='book_id', how='left')\n",
    "    [['book_id','title','average_rating','count']]\n",
    ")\n",
    "\n",
    "print(f\"Top {N} Popular Books:\")\n",
    "\n",
    "top_popular.head(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01a65da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "book_means = train_df.groupby('book_id')['rating'].mean()\n",
    "global_mean = train_df['rating'].mean()\n",
    "test_preds = test_df['book_id'].map(book_means).fillna(global_mean)\n",
    "rmse_baseline = root_mean_squared_error(test_df['rating'], test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5465cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision@N, Recall@N, HitRate@N\n",
    "\n",
    "truth = test_df.groupby('user_id')['book_id'].apply(set).to_dict()\n",
    "\n",
    "precisions, recalls, hits = [], [], []\n",
    "for user, actual in truth.items():\n",
    "    hit_count = len(actual & set(top_popular['book_id']))\n",
    "    precisions.append(hit_count / N)\n",
    "    recalls.append(hit_count / len(actual))\n",
    "    hits.append(int(hit_count > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "898b1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Metrics:\n",
      "\n",
      "RMSE:         0.9562\n",
      "Precision@10: 0.0669\n",
      "Recall@10:    0.0302\n",
      "HitRate@10:   0.4444\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBaseline Metrics:\\n\")\n",
    "\n",
    "print(f\"RMSE:         {np.mean(rmse_baseline):.4f}\")\n",
    "print(f\"Precision@{N}: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall@{N}:    {np.mean(recalls):.4f}\")\n",
    "print(f\"HitRate@{N}:   {np.mean(hits):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d992aa2",
   "metadata": {},
   "source": [
    "### new baseline using weighted rating\n",
    "\n",
    "A more sophisticated baseline. It still recommends popular items globally, but it uses a weighted rating formula (like IMDb's) that balances a book's average rating with the number of ratings it has received. This prevents books with few high ratings from dominating purely popular books with many moderate ratings.\n",
    "\n",
    "**IMDb Formula Implementation:**\n",
    "* `m`: Calculates a minimum vote threshold (here, the 90th percentile of rating counts). Books with fewer ratings than `m` will have their scores adjusted more significantly towards the global average.\n",
    "    \n",
    "* `C`: The prior belief, set to the `global_mean` rating from the training set.\n",
    "\n",
    "* `weighted_rating`: Applies the formula: `(v/(v+m))*R + (m/(v+m))*C`, where `v` is count, `R` is average rating.\n",
    "\n",
    "**Top-N Weighted:** Selects the top N books based on this calculated `weighted_rating`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c4b4ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d16e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg + count per book\n",
    "pop_stats = (\n",
    "    train_df\n",
    "    .groupby('book_id')\n",
    "    .agg(\n",
    "        avg_rating=('rating', 'mean'),\n",
    "        count_ratings=('rating', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb formula: (v/(v+m))*R + (m/(v+m))*C\n",
    "m = pop_stats['count_ratings'].quantile(0.90)\n",
    "C = train_df['rating'].mean()\n",
    "\n",
    "pop_stats['weighted_rating'] = (\n",
    "    (pop_stats['count_ratings'] / (pop_stats['count_ratings'] + m)) * pop_stats['avg_rating']\n",
    "  + (m / (pop_stats['count_ratings'] + m)) * C\n",
    ")\n",
    "\n",
    "# top‑N by weighted rating\n",
    "top_weighted_ids = pop_stats.nlargest(N, 'weighted_rating')['book_id'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6081bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_weighted = (\n",
    "    test_df\n",
    "    .merge(pop_stats[['book_id','weighted_rating']], on='book_id', how='left')\n",
    "    ['weighted_rating']\n",
    "    .fillna(C)          \n",
    ")\n",
    "\n",
    "rmse_weighted = rmse(test_df['rating'], preds_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aa1abf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, recall, hitrate calculation\n",
    "truth = test_df.groupby('user_id')['book_id'].apply(set).to_dict()\n",
    "\n",
    "prec_w, rec_w, hit_w = [], [], []\n",
    "\n",
    "for actual in truth.values():\n",
    "    hits = len(set(top_weighted_ids) & actual)\n",
    "    prec_w.append(hits / N)\n",
    "    rec_w.append(hits / len(actual) if actual else 0)\n",
    "    hit_w.append(int(hits > 0))\n",
    "\n",
    "precision_weighted = np.mean(prec_w)\n",
    "recall_weighted    = np.mean(rec_w)\n",
    "hitrate_weighted   = np.mean(hit_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a2a8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted-rating baseline Metrics\n",
      "RMSE:          0.9635\n",
      "Precision@10:  0.0437\n",
      "Recall@10:     0.0195\n",
      "HitRate@10:    0.3135\n"
     ]
    }
   ],
   "source": [
    "# Print weighted‑rating baseline metrics\n",
    "print(\"Weighted-rating baseline Metrics\")\n",
    "print(f\"RMSE:          {rmse_weighted:.4f}\")\n",
    "print(f\"Precision@{N}:  {precision_weighted:.4f}\")\n",
    "print(f\"Recall@{N}:     {recall_weighted:.4f}\")\n",
    "print(f\"HitRate@{N}:    {hitrate_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56253c28",
   "metadata": {},
   "source": [
    "## Memory-based collaborative filtering using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eaae740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Surprise dataset\n",
    "reader = Reader(rating_scale = (1, 5))\n",
    "\n",
    "data = Dataset.load_from_df(ratings[['user_id','book_id','rating']], reader)\n",
    "\n",
    "trainset, testset = surprise_train_test_split(data, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b11515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for top‑K metrics\n",
    "def precision_recall_hit_at_k(preds, k = 10, thresh = 4.0):\n",
    "    user_pred_true = defaultdict(list)\n",
    "    for uid, iid, true, est, _ in preds:\n",
    "        user_pred_true[uid].append((est, true))\n",
    "    \n",
    "    p_list, r_list, h_list = [], [], []\n",
    "\n",
    "    for ratings in user_pred_true.values():\n",
    "        ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "        top_k = ratings[:k]\n",
    "        n_rel = sum(true >= thresh for _, true in ratings)\n",
    "        n_rec = sum(true >= thresh for _, true in top_k)\n",
    "        p_list.append(n_rec/k)\n",
    "        r_list.append(n_rec/n_rel if n_rel else 0)\n",
    "        h_list.append(int(n_rec > 0))\n",
    "        \n",
    "    return {\n",
    "        'precision': np.mean(p_list),\n",
    "        'recall':    np.mean(r_list),\n",
    "        'hit_rate':  np.mean(h_list)\n",
    "    }\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f37369",
   "metadata": {},
   "source": [
    "### user-based collaborative filtering\n",
    "\n",
    "Recommends items that *similar users* liked. Similarity is based on rating patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43b7f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_uu = KNNBasic(sim_options = {'name':'cosine','user_based': True}, \n",
    "                   k = 30, \n",
    "                   verbose = False)\n",
    "\n",
    "algo_uu.fit(trainset)\n",
    "pred_uu = algo_uu.test(testset)\n",
    "\n",
    "rmse_uu = accuracy.rmse(pred_uu, verbose = False)\n",
    "m_uu    = precision_recall_hit_at_k(pred_uu, k = 10, thresh = 4.0)\n",
    "\n",
    "results.append({\n",
    "    'Model':       'User-User CF',\n",
    "    'RMSE':        rmse_uu,\n",
    "    'Precision@10': m_uu['precision'],\n",
    "    'Recall@10':    m_uu['recall'],\n",
    "    'Hit@10':       m_uu['hit_rate']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479819b",
   "metadata": {},
   "source": [
    "### item-based collaborative filtering\n",
    "\n",
    "Recommends items that are *similar* to items the user *already liked*. Similarity is based on users who rated both items similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb71c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ii = KNNBasic(sim_options = {'name':'cosine','user_based': False}, \n",
    "                   k = 30, \n",
    "                   verbose = False)\n",
    "\n",
    "algo_ii.fit(trainset)\n",
    "pred_ii = algo_ii.test(testset)\n",
    "\n",
    "rmse_ii = accuracy.rmse(pred_ii, verbose = False)\n",
    "m_ii    = precision_recall_hit_at_k(pred_ii, k = 10, thresh = 4.0)\n",
    "\n",
    "results.append({\n",
    "    'Model':       'Item-Item CF',\n",
    "    'RMSE':        rmse_ii,\n",
    "    'Precision@10': m_ii['precision'],\n",
    "    'Recall@10':    m_ii['recall'],\n",
    "    'Hit@10':       m_ii['hit_rate']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2eb53384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN-based CF Comparison:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hit@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a34092e2-21fe-4c15-886b-52c247d25f68",
       "rows": [
        [
         "0",
         "User-User CF",
         "0.9580381634192087",
         "0.7601237505949549",
         "0.5311807594934783",
         "0.9973346025702047"
        ],
        [
         "1",
         "Item-Item CF",
         "0.8928967220408549",
         "0.7179343169919086",
         "0.5019354417258618",
         "0.9967634459781056"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Hit@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User-User CF</td>\n",
       "      <td>0.958038</td>\n",
       "      <td>0.760124</td>\n",
       "      <td>0.531181</td>\n",
       "      <td>0.997335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item CF</td>\n",
       "      <td>0.892897</td>\n",
       "      <td>0.717934</td>\n",
       "      <td>0.501935</td>\n",
       "      <td>0.996763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model      RMSE  Precision@10  Recall@10    Hit@10\n",
       "0  User-User CF  0.958038      0.760124   0.531181  0.997335\n",
       "1  Item-Item CF  0.892897      0.717934   0.501935  0.996763"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn = pd.DataFrame(results)\n",
    "print(\"\\nKNN-based CF Comparison:\\n\")\n",
    "\n",
    "df_knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f381d",
   "metadata": {},
   "source": [
    "## Model‑based CF using SVD matrix factorization\n",
    "\n",
    "Uses Matrix Factorization - SVD -  to learn latent features (embeddings) for users and items. It predicts ratings by taking the dot product of user and item latent vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a735ed0",
   "metadata": {},
   "source": [
    "### basic SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8d71d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_svd = SVD(random_state = 42)\n",
    "algo_svd.fit(trainset)\n",
    "pred_svd = algo_svd.test(testset)\n",
    "\n",
    "rmse_svd = accuracy.rmse(pred_svd, verbose = False)\n",
    "metrics_svd = precision_recall_hit_at_k(pred_svd, k = 10, thresh = 4.0)\n",
    "results.append({\n",
    "    'Model':       'SVD (MF)',\n",
    "    'RMSE':        rmse_svd,\n",
    "    'Precision@10': metrics_svd['precision'],\n",
    "    'Recall@10':    metrics_svd['recall'],\n",
    "    'Hit@10':       metrics_svd['hit_rate']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda7009",
   "metadata": {},
   "source": [
    "### SVD with bias and parameters\n",
    "\n",
    "- `n_factors = 50`: Number of latent dimensions to learn.\n",
    "\n",
    " - `biased = True`: Includes baseline estimates (user/item biases) in the prediction, often improving accuracy.\n",
    "\n",
    "- `reg_all = 0.02`: Regularization term to prevent overfitting.\n",
    "        \n",
    "- `lr_all = 0.005`: Learning rate for the optimization algorithm (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "49dabb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_svd_bias = SVD(\n",
    "    n_factors = 50,    # number of latent factors\n",
    "    biased = True,     # include user/item biases\n",
    "    reg_all = 0.02,    # regularization\n",
    "    # lr = 0.005,    # learning rate\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "algo_svd_bias.fit(trainset)\n",
    "pred_svd_bias = algo_svd_bias.test(testset)\n",
    "\n",
    "rmse_svd = accuracy.rmse(pred_svd_bias, verbose = False)\n",
    "metrics_svd = precision_recall_hit_at_k(pred_svd_bias, k = 10, thresh = 4.0)\n",
    "\n",
    "results.append({\n",
    "    'Model':       'SVD with bias (MF)',\n",
    "    'RMSE':        rmse_svd,\n",
    "    'Precision@10': metrics_svd['precision'],\n",
    "    'Recall@10':    metrics_svd['recall'],\n",
    "    'Hit@10':       metrics_svd['hit_rate']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7cd2919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVD based CF results:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hit@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d5c17eab-33f7-43c3-8027-ad8560e9604d",
       "rows": [
        [
         "0",
         "User-User CF",
         "0.9580381634192087",
         "0.7601237505949549",
         "0.5311807594934783",
         "0.9973346025702047"
        ],
        [
         "1",
         "Item-Item CF",
         "0.8928967220408549",
         "0.7179343169919086",
         "0.5019354417258618",
         "0.9967634459781056"
        ],
        [
         "2",
         "SVD (MF)",
         "0.8491774464078112",
         "0.775478343645883",
         "0.5442745509154961",
         "0.997715373631604"
        ],
        [
         "3",
         "SVD with bias (MF)",
         "0.8472753810903361",
         "0.7773631603998097",
         "0.5457150598082513",
         "0.9980009519276535"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Hit@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User-User CF</td>\n",
       "      <td>0.958038</td>\n",
       "      <td>0.760124</td>\n",
       "      <td>0.531181</td>\n",
       "      <td>0.997335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item CF</td>\n",
       "      <td>0.892897</td>\n",
       "      <td>0.717934</td>\n",
       "      <td>0.501935</td>\n",
       "      <td>0.996763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD (MF)</td>\n",
       "      <td>0.849177</td>\n",
       "      <td>0.775478</td>\n",
       "      <td>0.544275</td>\n",
       "      <td>0.997715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD with bias (MF)</td>\n",
       "      <td>0.847275</td>\n",
       "      <td>0.777363</td>\n",
       "      <td>0.545715</td>\n",
       "      <td>0.998001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model      RMSE  Precision@10  Recall@10    Hit@10\n",
       "0        User-User CF  0.958038      0.760124   0.531181  0.997335\n",
       "1        Item-Item CF  0.892897      0.717934   0.501935  0.996763\n",
       "2            SVD (MF)  0.849177      0.775478   0.544275  0.997715\n",
       "3  SVD with bias (MF)  0.847275      0.777363   0.545715  0.998001"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svd = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nSVD based CF results:\\n\")\n",
    "\n",
    "df_svd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5421770",
   "metadata": {},
   "source": [
    "### displaying recs for actual users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb8ef41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 7531 Recommendations\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User-User CF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item-Item CF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD (MF)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD with bias (MF)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "af1258ca-63e0-4fed-bb48-2b46bef8ea75",
       "rows": [
        [
         "0",
         "The Fault in Our Stars",
         "Room",
         "The Fault in Our Stars",
         "The Giver (The Giver, #1)"
        ],
        [
         "1",
         "Les Misérables",
         "Snow Flower and the Secret Fan",
         "Catching Fire (The Hunger Games, #2)",
         "Catching Fire (The Hunger Games, #2)"
        ],
        [
         "2",
         "Wonderstruck",
         "Stones from the River",
         "Honolulu",
         "Room"
        ],
        [
         "3",
         "Stones from the River",
         "The Book of Ruth",
         "Wonderstruck",
         "Wonderstruck"
        ],
        [
         "4",
         "Let's Pretend This Never Happened: A Mostly True Memoir",
         "Wonderstruck",
         "The Giver (The Giver, #1)",
         "Moloka'i"
        ],
        [
         "5",
         "The English Spy (Gabriel Allon, #15)",
         "Catching Fire (The Hunger Games, #2)",
         "The Light Between Oceans",
         "Les Misérables"
        ],
        [
         "6",
         "Room",
         "The Fault in Our Stars",
         "Moloka'i",
         "The Fault in Our Stars"
        ],
        [
         "7",
         "Moloka'i",
         "The Girl on the Train",
         "The English Spy (Gabriel Allon, #15)",
         "The English Spy (Gabriel Allon, #15)"
        ],
        [
         "8",
         "Honolulu",
         "Les Misérables",
         "Les Misérables",
         "Snow Flower and the Secret Fan"
        ],
        [
         "9",
         "Shanghai Girls (Shanghai Girls #1)",
         "Honolulu",
         "Let's Pretend This Never Happened: A Mostly True Memoir",
         "The Girl on the Train"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-User CF</th>\n",
       "      <th>Item-Item CF</th>\n",
       "      <th>SVD (MF)</th>\n",
       "      <th>SVD with bias (MF)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>Room</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>The Giver (The Giver, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les Misérables</td>\n",
       "      <td>Snow Flower and the Secret Fan</td>\n",
       "      <td>Catching Fire (The Hunger Games, #2)</td>\n",
       "      <td>Catching Fire (The Hunger Games, #2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderstruck</td>\n",
       "      <td>Stones from the River</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stones from the River</td>\n",
       "      <td>The Book of Ruth</td>\n",
       "      <td>Wonderstruck</td>\n",
       "      <td>Wonderstruck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let's Pretend This Never Happened: A Mostly Tr...</td>\n",
       "      <td>Wonderstruck</td>\n",
       "      <td>The Giver (The Giver, #1)</td>\n",
       "      <td>Moloka'i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The English Spy (Gabriel Allon, #15)</td>\n",
       "      <td>Catching Fire (The Hunger Games, #2)</td>\n",
       "      <td>The Light Between Oceans</td>\n",
       "      <td>Les Misérables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Room</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>Moloka'i</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Moloka'i</td>\n",
       "      <td>The Girl on the Train</td>\n",
       "      <td>The English Spy (Gabriel Allon, #15)</td>\n",
       "      <td>The English Spy (Gabriel Allon, #15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Les Misérables</td>\n",
       "      <td>Les Misérables</td>\n",
       "      <td>Snow Flower and the Secret Fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shanghai Girls (Shanghai Girls #1)</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Let's Pretend This Never Happened: A Mostly Tr...</td>\n",
       "      <td>The Girl on the Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        User-User CF  \\\n",
       "0                             The Fault in Our Stars   \n",
       "1                                     Les Misérables   \n",
       "2                                       Wonderstruck   \n",
       "3                              Stones from the River   \n",
       "4  Let's Pretend This Never Happened: A Mostly Tr...   \n",
       "5               The English Spy (Gabriel Allon, #15)   \n",
       "6                                               Room   \n",
       "7                                           Moloka'i   \n",
       "8                                           Honolulu   \n",
       "9                 Shanghai Girls (Shanghai Girls #1)   \n",
       "\n",
       "                           Item-Item CF  \\\n",
       "0                                  Room   \n",
       "1        Snow Flower and the Secret Fan   \n",
       "2                 Stones from the River   \n",
       "3                      The Book of Ruth   \n",
       "4                          Wonderstruck   \n",
       "5  Catching Fire (The Hunger Games, #2)   \n",
       "6                The Fault in Our Stars   \n",
       "7                 The Girl on the Train   \n",
       "8                        Les Misérables   \n",
       "9                              Honolulu   \n",
       "\n",
       "                                            SVD (MF)  \\\n",
       "0                             The Fault in Our Stars   \n",
       "1               Catching Fire (The Hunger Games, #2)   \n",
       "2                                           Honolulu   \n",
       "3                                       Wonderstruck   \n",
       "4                          The Giver (The Giver, #1)   \n",
       "5                           The Light Between Oceans   \n",
       "6                                           Moloka'i   \n",
       "7               The English Spy (Gabriel Allon, #15)   \n",
       "8                                     Les Misérables   \n",
       "9  Let's Pretend This Never Happened: A Mostly Tr...   \n",
       "\n",
       "                     SVD with bias (MF)  \n",
       "0             The Giver (The Giver, #1)  \n",
       "1  Catching Fire (The Hunger Games, #2)  \n",
       "2                                  Room  \n",
       "3                          Wonderstruck  \n",
       "4                              Moloka'i  \n",
       "5                        Les Misérables  \n",
       "6                The Fault in Our Stars  \n",
       "7  The English Spy (Gabriel Allon, #15)  \n",
       "8        Snow Flower and the Secret Fan  \n",
       "9                 The Girl on the Train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 30102 Recommendations\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User-User CF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item-Item CF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD (MF)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD with bias (MF)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c0469692-1289-4b52-b24f-0a51a4e248af",
       "rows": [
        [
         "0",
         "Fruits Basket, Vol. 4",
         "Hedda Gabler",
         "Watchmen",
         "Watchmen"
        ],
        [
         "1",
         "Fruits Basket, Vol. 3",
         "Hana-Kimi, Vol. 1 (Hana-Kimi, #1)",
         "Fruits Basket, Vol. 4",
         "The Call of the Wild"
        ],
        [
         "2",
         "One Grave at a Time (Night Huntress, #6)",
         "Watchmen",
         "The Call of Cthulhu and Other Weird Stories",
         "Animal Farm"
        ],
        [
         "3",
         "The Call of Cthulhu and Other Weird Stories",
         "Romeo and Juliet",
         "A Streetcar Named Desire",
         "Fruits Basket, Vol. 3"
        ],
        [
         "4",
         "Watchmen",
         "The Call of the Wild",
         "Animal Farm",
         "Romeo and Juliet"
        ],
        [
         "5",
         "Animal Farm",
         "The Great Gatsby",
         "Fruits Basket, Vol. 3",
         "A Streetcar Named Desire"
        ],
        [
         "6",
         "Hana-Kimi, Vol. 1 (Hana-Kimi, #1)",
         "Halfway to the Grave (Night Huntress, #1)",
         "Romeo and Juliet",
         "Halfway to the Grave (Night Huntress, #1)"
        ],
        [
         "7",
         "Eternal Kiss of Darkness (Night Huntress World, #2)",
         "Fruits Basket, Vol. 4",
         "Bloody Bones (Anita Blake, Vampire Hunter #5)",
         "The Call of Cthulhu and Other Weird Stories"
        ],
        [
         "8",
         "The Lunatic Cafe (Anita Blake, Vampire Hunter #4)",
         "Fruits Basket, Vol. 3",
         "The Indian in the Cupboard (The Indian in the Cupboard, #1)",
         "One Grave at a Time (Night Huntress, #6)"
        ],
        [
         "9",
         "A Streetcar Named Desire",
         "The Call of Cthulhu and Other Weird Stories",
         "One Grave at a Time (Night Huntress, #6)",
         "Fruits Basket, Vol. 4"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-User CF</th>\n",
       "      <th>Item-Item CF</th>\n",
       "      <th>SVD (MF)</th>\n",
       "      <th>SVD with bias (MF)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fruits Basket, Vol. 4</td>\n",
       "      <td>Hedda Gabler</td>\n",
       "      <td>Watchmen</td>\n",
       "      <td>Watchmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fruits Basket, Vol. 3</td>\n",
       "      <td>Hana-Kimi, Vol. 1 (Hana-Kimi, #1)</td>\n",
       "      <td>Fruits Basket, Vol. 4</td>\n",
       "      <td>The Call of the Wild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Grave at a Time (Night Huntress, #6)</td>\n",
       "      <td>Watchmen</td>\n",
       "      <td>The Call of Cthulhu and Other Weird Stories</td>\n",
       "      <td>Animal Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Call of Cthulhu and Other Weird Stories</td>\n",
       "      <td>Romeo and Juliet</td>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>Fruits Basket, Vol. 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watchmen</td>\n",
       "      <td>The Call of the Wild</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>Romeo and Juliet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>Fruits Basket, Vol. 3</td>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hana-Kimi, Vol. 1 (Hana-Kimi, #1)</td>\n",
       "      <td>Halfway to the Grave (Night Huntress, #1)</td>\n",
       "      <td>Romeo and Juliet</td>\n",
       "      <td>Halfway to the Grave (Night Huntress, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eternal Kiss of Darkness (Night Huntress World...</td>\n",
       "      <td>Fruits Basket, Vol. 4</td>\n",
       "      <td>Bloody Bones (Anita Blake, Vampire Hunter #5)</td>\n",
       "      <td>The Call of Cthulhu and Other Weird Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lunatic Cafe (Anita Blake, Vampire Hunter #4)</td>\n",
       "      <td>Fruits Basket, Vol. 3</td>\n",
       "      <td>The Indian in the Cupboard (The Indian in the ...</td>\n",
       "      <td>One Grave at a Time (Night Huntress, #6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>The Call of Cthulhu and Other Weird Stories</td>\n",
       "      <td>One Grave at a Time (Night Huntress, #6)</td>\n",
       "      <td>Fruits Basket, Vol. 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        User-User CF  \\\n",
       "0                              Fruits Basket, Vol. 4   \n",
       "1                              Fruits Basket, Vol. 3   \n",
       "2           One Grave at a Time (Night Huntress, #6)   \n",
       "3        The Call of Cthulhu and Other Weird Stories   \n",
       "4                                           Watchmen   \n",
       "5                                        Animal Farm   \n",
       "6                  Hana-Kimi, Vol. 1 (Hana-Kimi, #1)   \n",
       "7  Eternal Kiss of Darkness (Night Huntress World...   \n",
       "8  The Lunatic Cafe (Anita Blake, Vampire Hunter #4)   \n",
       "9                           A Streetcar Named Desire   \n",
       "\n",
       "                                  Item-Item CF  \\\n",
       "0                                 Hedda Gabler   \n",
       "1            Hana-Kimi, Vol. 1 (Hana-Kimi, #1)   \n",
       "2                                     Watchmen   \n",
       "3                             Romeo and Juliet   \n",
       "4                         The Call of the Wild   \n",
       "5                             The Great Gatsby   \n",
       "6    Halfway to the Grave (Night Huntress, #1)   \n",
       "7                        Fruits Basket, Vol. 4   \n",
       "8                        Fruits Basket, Vol. 3   \n",
       "9  The Call of Cthulhu and Other Weird Stories   \n",
       "\n",
       "                                            SVD (MF)  \\\n",
       "0                                           Watchmen   \n",
       "1                              Fruits Basket, Vol. 4   \n",
       "2        The Call of Cthulhu and Other Weird Stories   \n",
       "3                           A Streetcar Named Desire   \n",
       "4                                        Animal Farm   \n",
       "5                              Fruits Basket, Vol. 3   \n",
       "6                                   Romeo and Juliet   \n",
       "7      Bloody Bones (Anita Blake, Vampire Hunter #5)   \n",
       "8  The Indian in the Cupboard (The Indian in the ...   \n",
       "9           One Grave at a Time (Night Huntress, #6)   \n",
       "\n",
       "                            SVD with bias (MF)  \n",
       "0                                     Watchmen  \n",
       "1                         The Call of the Wild  \n",
       "2                                  Animal Farm  \n",
       "3                        Fruits Basket, Vol. 3  \n",
       "4                             Romeo and Juliet  \n",
       "5                     A Streetcar Named Desire  \n",
       "6    Halfway to the Grave (Night Huntress, #1)  \n",
       "7  The Call of Cthulhu and Other Weird Stories  \n",
       "8     One Grave at a Time (Night Huntress, #6)  \n",
       "9                        Fruits Basket, Vol. 4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_top_n(predictions, n = 10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid in top_n:\n",
    "        top_n[uid].sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = top_n[uid][:n]\n",
    "    return top_n\n",
    "\n",
    "top10_uu  = get_top_n(pred_uu,  n = 10)\n",
    "top10_ii  = get_top_n(pred_ii,  n = 10)\n",
    "top10_mf  = get_top_n(pred_svd, n = 10)\n",
    "top10_mfb = get_top_n(pred_svd_bias, n = 10)\n",
    "\n",
    "models = {\n",
    "    'User-User CF': top10_uu,\n",
    "    'Item-Item CF': top10_ii,\n",
    "    'SVD (MF)'    : top10_mf,\n",
    "    'SVD with bias (MF)': top10_mfb\n",
    "}\n",
    "\n",
    "# users\n",
    "user_ids = [7531, 30102]\n",
    "\n",
    "for uid in user_ids:\n",
    "    key = uid if uid in top10_uu else str(uid)\n",
    "\n",
    "    # coolect each model's top‑10 titles\n",
    "    data = {}\n",
    "    for name, top_dict in models.items():\n",
    "        recs   = top_dict.get(key, [])\n",
    "        titles = [\n",
    "            books.loc[books.book_id == int(iid), 'title'].iloc[0]\n",
    "            for iid, _ in recs\n",
    "        ]\n",
    "        titles += [''] * (10 - len(titles))\n",
    "        data[name] = titles\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"\\nUser {uid} Recommendations\\n\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3ddb5",
   "metadata": {},
   "source": [
    "## content-based filtering\n",
    "\n",
    "**Purpose:** recommends items based on their textual content (description, tags) similarity to items a user liked previously. It doesn't rely on other users' behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4f88d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anusha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aad8fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat description + tags to create a new field\n",
    "books['content'] = (\n",
    "    books['description'].fillna('') + ' ' +\n",
    "    books['unique_tags_str'].fillna('')\n",
    ")\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)     # strip punctuation\n",
    "    tokens = text.split()\n",
    "    tokens = [tok for tok in tokens if tok not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "books['content_clean'] = books['content'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e2da228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix shape: (10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# compute tf‑idf & cosine similarity\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(books['content_clean'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "print(f\"Cosine similarity matrix shape: {cosine_sim.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2c3dd",
   "metadata": {},
   "source": [
    "`cosine_sim` is a matrix where `cosine_sim[i][j]` is the content similarity between book `i` and book `j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "11683409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from book_id to index \n",
    "book_to_idx = {bid: idx for idx, bid in enumerate(books['book_id'])}\n",
    "idx_to_book = {idx: bid for bid, idx in book_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "39ff1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get liked titles & recommendations\n",
    "def content_recommendations_for_user(user_id, ratings_df, books_df,\n",
    "                                     cosine_sim, book_to_idx,\n",
    "                                     top_n = 10, threshold = 4.0):\n",
    "    \n",
    "    # find books the user rated ≥ threshold\n",
    "    liked_ids = ratings_df[\n",
    "        (ratings_df.user_id == user_id) &\n",
    "        (ratings_df.rating  >= threshold)\n",
    "    ]['book_id'].unique()\n",
    "    \n",
    "    liked_titles = books_df.loc[\n",
    "        books_df.book_id.isin(liked_ids),\n",
    "        ['book_id','title']\n",
    "    ]\n",
    "    \n",
    "    # aggregate similarity scores\n",
    "    agg_scores = {}\n",
    "    for bid in liked_ids:\n",
    "        idx = book_to_idx.get(bid)\n",
    "        if idx is None: \n",
    "            continue\n",
    "        for other_idx, score in enumerate(cosine_sim[idx]):\n",
    "            agg_scores[other_idx] = agg_scores.get(other_idx, 0) + score\n",
    "    \n",
    "    # remove already‑seen books\n",
    "    for bid in liked_ids:\n",
    "        idx = book_to_idx.get(bid)\n",
    "        if idx is not None:\n",
    "            agg_scores.pop(idx, None)\n",
    "    \n",
    "    # select top‑N\n",
    "    top_indices = sorted(\n",
    "        agg_scores.keys(),\n",
    "        key = lambda i: agg_scores[i],\n",
    "        reverse = True\n",
    "    )[:top_n]\n",
    "\n",
    "    rec_book_ids = [idx_to_book[idx] for idx in top_indices]\n",
    "    rec_titles = books_df.loc[\n",
    "        books_df.book_id.isin(rec_book_ids),\n",
    "        ['book_id','title']\n",
    "    ]\n",
    "    \n",
    "    return liked_titles, rec_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3981 liked these books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8d9380dd-024b-4111-8d71-a8b023ba2940",
       "rows": [
        [
         "38",
         "39",
         "A Game of Thrones (A Song of Ice and Fire, #1)"
        ],
        [
         "47",
         "48",
         "Fahrenheit 451"
        ],
        [
         "64",
         "65",
         "Slaughterhouse-Five"
        ],
        [
         "83",
         "84",
         "Jurassic Park (Jurassic Park, #1)"
        ],
        [
         "103",
         "104",
         "The Road"
        ],
        [
         "109",
         "110",
         "A Clash of Kings  (A Song of Ice and Fire, #2)"
        ],
        [
         "134",
         "135",
         "A Storm of Swords (A Song of Ice and Fire, #3)"
        ],
        [
         "154",
         "155",
         "The Two Towers (The Lord of the Rings, #2)"
        ],
        [
         "157",
         "158",
         "Charlie and the Chocolate Factory (Charlie Bucket, #1)"
        ],
        [
         "160",
         "161",
         "The Return of the King (The Lord of the Rings, #3)"
        ],
        [
         "164",
         "165",
         "A Feast for Crows (A Song of Ice and Fire, #4)"
        ],
        [
         "188",
         "189",
         "The Lord of the Rings (The Lord of the Rings, #1-3)"
        ],
        [
         "190",
         "191",
         "Watchmen"
        ],
        [
         "235",
         "236",
         "Into Thin Air: A Personal Account of the Mount Everest Disaster"
        ],
        [
         "238",
         "239",
         "World War Z: An Oral History of the Zombie War"
        ],
        [
         "311",
         "312",
         "The Graveyard Book"
        ],
        [
         "321",
         "322",
         "Neverwhere"
        ],
        [
         "370",
         "371",
         "Stranger in a Strange Land"
        ],
        [
         "399",
         "400",
         "Neuromancer"
        ],
        [
         "502",
         "503",
         "2001: A Space Odyssey (Space Odyssey, #1)"
        ],
        [
         "515",
         "516",
         "The Amazing Adventures of Kavalier & Clay"
        ],
        [
         "531",
         "532",
         "Batman: Year One"
        ],
        [
         "567",
         "568",
         "Batman: The Dark Knight Returns (The Dark Knight Saga, #1)"
        ],
        [
         "632",
         "633",
         "Starship Troopers"
        ],
        [
         "734",
         "735",
         "Batman: The Killing Joke"
        ],
        [
         "742",
         "743",
         "Lamb: The Gospel According to Biff, Christ's Childhood Pal"
        ],
        [
         "814",
         "815",
         "No Country for Old Men"
        ],
        [
         "896",
         "897",
         "Rendezvous with Rama (Rama, #1)"
        ],
        [
         "909",
         "910",
         "Old Man's War (Old Man's War, #1)"
        ],
        [
         "1089",
         "1090",
         "House of Leaves"
        ],
        [
         "1095",
         "1096",
         "America (The Book): A Citizen's Guide to Democracy Inaction"
        ],
        [
         "1190",
         "1191",
         "Ringworld (Ringworld, #1)"
        ],
        [
         "1380",
         "1381",
         "The Eyre Affair (Thursday Next, #1)"
        ],
        [
         "1640",
         "1641",
         "Something Wicked This Way Comes (Green Town, #2)"
        ],
        [
         "1872",
         "1873",
         "The Yiddish Policemen's Union"
        ],
        [
         "1880",
         "1881",
         "The Mote in God's Eye"
        ],
        [
         "2083",
         "2084",
         "Anathem"
        ],
        [
         "2126",
         "2127",
         "Olivia"
        ],
        [
         "2451",
         "2452",
         "Pyramids (Discworld, #7)"
        ],
        [
         "2468",
         "2469",
         "Lords and Ladies (Discworld, #14; Witches #4)"
        ],
        [
         "2610",
         "2611",
         "A Hat Full of Sky (Discworld, #32; Tiffany Aching, #2)"
        ],
        [
         "2657",
         "2658",
         "Moving Pictures (Discworld, #10; Industrial Revolution, #1)"
        ],
        [
         "2692",
         "2693",
         "A Fire Upon the Deep (Zones of Thought, #1)"
        ],
        [
         "2759",
         "2760",
         "The League of Extraordinary Gentlemen, Vol. 1"
        ],
        [
         "2781",
         "2782",
         "Transmetropolitan, Vol. 1: Back on the Street (Transmetropolitan, #1)"
        ],
        [
         "2880",
         "2881",
         "Making Money (Discworld, #36; Moist Von Lipwig, #2)"
        ],
        [
         "2999",
         "3000",
         "Jingo (Discworld, #21; City Watch, #4)"
        ],
        [
         "3005",
         "3006",
         "Count Zero (Sprawl, #2)"
        ],
        [
         "3012",
         "3013",
         "The Last Colony (Old Man's War #3)"
        ],
        [
         "3035",
         "3036",
         "Fluke: Or, I Know Why the Winged Whale Sings"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 81
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>A Game of Thrones (A Song of Ice and Fire, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Fahrenheit 451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>Slaughterhouse-Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>Jurassic Park (Jurassic Park, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>The Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>8880</td>\n",
       "      <td>Transmetropolitan, Vol. 5: Lonely City (Transm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>8961</td>\n",
       "      <td>Footfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>9428</td>\n",
       "      <td>Johnny Mnemonic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>9607</td>\n",
       "      <td>Singularity Sky (Eschaton, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>9626</td>\n",
       "      <td>Transmetropolitan, Vol. 4: The New Scum (Trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                              title\n",
       "38         39     A Game of Thrones (A Song of Ice and Fire, #1)\n",
       "47         48                                     Fahrenheit 451\n",
       "64         65                                Slaughterhouse-Five\n",
       "83         84                  Jurassic Park (Jurassic Park, #1)\n",
       "103       104                                           The Road\n",
       "...       ...                                                ...\n",
       "8879     8880  Transmetropolitan, Vol. 5: Lonely City (Transm...\n",
       "8960     8961                                           Footfall\n",
       "9427     9428                                    Johnny Mnemonic\n",
       "9606     9607                     Singularity Sky (Eschaton, #1)\n",
       "9625     9626  Transmetropolitan, Vol. 4: The New Scum (Trans...\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 content-based recommendations for user 3981:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d3882dc8-ae4d-42e6-a768-993664075856",
       "rows": [
        [
         "509",
         "510",
         "The Great Hunt (Wheel of Time, #2)"
        ],
        [
         "971",
         "972",
         "Journey to the Center of the Earth (Extraordinary Voyages, #3)"
        ],
        [
         "1118",
         "1119",
         "A Crown of Swords (Wheel of Time, #7)"
        ],
        [
         "1203",
         "1204",
         "The Invisible Man"
        ],
        [
         "1342",
         "1343",
         "The Light Fantastic (Discworld, #2; Rincewind #2)"
        ],
        [
         "4584",
         "4585",
         "Foundation and Chaos (Second Foundation Trilogy #2)"
        ],
        [
         "6014",
         "6015",
         "The Atlantis World (The Origin Mystery, #3)"
        ],
        [
         "6430",
         "6431",
         "Path of Destruction (Star Wars: Darth Bane, #1)"
        ],
        [
         "7920",
         "7921",
         "2BR02B"
        ],
        [
         "9407",
         "9408",
         "The Darkest Road (The Fionavar Tapestry, #3)"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>510</td>\n",
       "      <td>The Great Hunt (Wheel of Time, #2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>972</td>\n",
       "      <td>Journey to the Center of the Earth (Extraordin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1119</td>\n",
       "      <td>A Crown of Swords (Wheel of Time, #7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1204</td>\n",
       "      <td>The Invisible Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>1343</td>\n",
       "      <td>The Light Fantastic (Discworld, #2; Rincewind #2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>4585</td>\n",
       "      <td>Foundation and Chaos (Second Foundation Trilog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>6015</td>\n",
       "      <td>The Atlantis World (The Origin Mystery, #3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>6431</td>\n",
       "      <td>Path of Destruction (Star Wars: Darth Bane, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>7921</td>\n",
       "      <td>2BR02B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9407</th>\n",
       "      <td>9408</td>\n",
       "      <td>The Darkest Road (The Fionavar Tapestry, #3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                              title\n",
       "509       510                 The Great Hunt (Wheel of Time, #2)\n",
       "971       972  Journey to the Center of the Earth (Extraordin...\n",
       "1118     1119              A Crown of Swords (Wheel of Time, #7)\n",
       "1203     1204                                  The Invisible Man\n",
       "1342     1343  The Light Fantastic (Discworld, #2; Rincewind #2)\n",
       "4584     4585  Foundation and Chaos (Second Foundation Trilog...\n",
       "6014     6015        The Atlantis World (The Origin Mystery, #3)\n",
       "6430     6431    Path of Destruction (Star Wars: Darth Bane, #1)\n",
       "7920     7921                                             2BR02B\n",
       "9407     9408       The Darkest Road (The Fionavar Tapestry, #3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example for user 3981\n",
    "user_id = 3981\n",
    "liked, recs = content_recommendations_for_user(\n",
    "    user_id, ratings, books,\n",
    "    cosine_sim, book_to_idx,\n",
    "    top_n = 10, threshold = 4.0\n",
    ")\n",
    "\n",
    "print(f\"User {user_id} liked these books:\")\n",
    "display(liked)\n",
    "\n",
    "print(f\"\\nTop-10 content-based recommendations for user {user_id}:\")\n",
    "display(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b1d9c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 7531 liked these books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1ae0dc1f-f84a-4614-9eb5-5ea93ab4e542",
       "rows": [
        [
         "0",
         "1",
         "The Hunger Games (The Hunger Games, #1)"
        ],
        [
         "5",
         "6",
         "The Fault in Our Stars"
        ],
        [
         "7",
         "8",
         "The Catcher in the Rye"
        ],
        [
         "10",
         "11",
         "The Kite Runner"
        ],
        [
         "15",
         "16",
         "The Girl with the Dragon Tattoo (Millennium, #1)"
        ],
        [
         "16",
         "17",
         "Catching Fire (The Hunger Games, #2)"
        ],
        [
         "19",
         "20",
         "Mockingjay (The Hunger Games, #3)"
        ],
        [
         "21",
         "22",
         "The Lovely Bones"
        ],
        [
         "29",
         "30",
         "Gone Girl"
        ],
        [
         "30",
         "31",
         "The Help"
        ],
        [
         "46",
         "47",
         "The Book Thief"
        ],
        [
         "60",
         "61",
         "The Girl on the Train"
        ],
        [
         "74",
         "75",
         "Bridget Jones's Diary (Bridget Jones, #1)"
        ],
        [
         "89",
         "90",
         "The Outsiders"
        ],
        [
         "99",
         "100",
         "The Poisonwood Bible"
        ],
        [
         "108",
         "109",
         "Les Misérables"
        ],
        [
         "111",
         "112",
         "Me Before You (Me Before You, #1)"
        ],
        [
         "117",
         "118",
         "The Joy Luck Club"
        ],
        [
         "123",
         "124",
         "Room"
        ],
        [
         "134",
         "135",
         "A Storm of Swords (A Song of Ice and Fire, #3)"
        ],
        [
         "135",
         "136",
         "Divine Secrets of the Ya-Ya Sisterhood"
        ],
        [
         "142",
         "143",
         "All the Light We Cannot See"
        ],
        [
         "149",
         "150",
         "The Red Tent"
        ],
        [
         "184",
         "185",
         "The Night Circus"
        ],
        [
         "189",
         "190",
         "Wild: From Lost to Found on the Pacific Crest Trail"
        ],
        [
         "224",
         "225",
         "East of Eden"
        ],
        [
         "234",
         "235",
         "The Husband's Secret"
        ],
        [
         "244",
         "245",
         "Bridge to Terabithia"
        ],
        [
         "248",
         "249",
         "Extremely Loud and Incredibly Close"
        ],
        [
         "249",
         "250",
         "Wonder"
        ],
        [
         "257",
         "258",
         "The Shadow of the Wind (The Cemetery of Forgotten Books,  #1)"
        ],
        [
         "260",
         "261",
         "Under the Tuscan Sun"
        ],
        [
         "261",
         "262",
         "Big Little Lies"
        ],
        [
         "264",
         "265",
         "A Tree Grows in Brooklyn"
        ],
        [
         "266",
         "267",
         "The Nightingale"
        ],
        [
         "271",
         "272",
         "Like Water for Chocolate"
        ],
        [
         "272",
         "273",
         "Snow Flower and the Secret Fan"
        ],
        [
         "309",
         "310",
         "Good in Bed (Cannie Shapiro, #1)"
        ],
        [
         "310",
         "311",
         "The Thorn Birds"
        ],
        [
         "312",
         "313",
         "The Light Between Oceans"
        ],
        [
         "320",
         "321",
         "Where the Red Fern Grows"
        ],
        [
         "380",
         "381",
         "Where the Heart Is"
        ],
        [
         "395",
         "396",
         "Hotel on the Corner of Bitter and Sweet"
        ],
        [
         "416",
         "417",
         "The Thirteenth Tale"
        ],
        [
         "437",
         "438",
         "What Alice Forgot"
        ],
        [
         "514",
         "515",
         "The Prince of Tides"
        ],
        [
         "565",
         "566",
         "After You (Me Before You, #2)"
        ],
        [
         "566",
         "567",
         "The Language of Flowers"
        ],
        [
         "609",
         "610",
         "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics"
        ],
        [
         "629",
         "630",
         "Lean In: Women, Work, and the Will to Lead"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 94
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Catcher in the Rye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>The Kite Runner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>The Girl with the Dragon Tattoo (Millennium, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6047</td>\n",
       "      <td>Honolulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>6281</td>\n",
       "      <td>The English Spy (Gabriel Allon, #15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043</th>\n",
       "      <td>7044</td>\n",
       "      <td>The Ship of Brides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>7775</td>\n",
       "      <td>Love and War (North and South, #2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>9545</td>\n",
       "      <td>And Ladies of the Club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                             title\n",
       "0           1           The Hunger Games (The Hunger Games, #1)\n",
       "5           6                            The Fault in Our Stars\n",
       "7           8                            The Catcher in the Rye\n",
       "10         11                                   The Kite Runner\n",
       "15         16  The Girl with the Dragon Tattoo (Millennium, #1)\n",
       "...       ...                                               ...\n",
       "6046     6047                                          Honolulu\n",
       "6280     6281              The English Spy (Gabriel Allon, #15)\n",
       "7043     7044                                The Ship of Brides\n",
       "7774     7775                Love and War (North and South, #2)\n",
       "9544     9545                            And Ladies of the Club\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 content-based recommendations for user 7531:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "140e320f-672d-4584-ad76-3a4551546a8b",
       "rows": [
        [
         "971",
         "972",
         "Journey to the Center of the Earth (Extraordinary Voyages, #3)"
        ],
        [
         "1738",
         "1739",
         "The Bonfire of the Vanities"
        ],
        [
         "3437",
         "3438",
         "فلتغفري"
        ],
        [
         "4263",
         "4264",
         "ذاكرة الجسد"
        ],
        [
         "4299",
         "4300",
         "The Ladies' Room"
        ],
        [
         "5930",
         "5931",
         "Adam Bede"
        ],
        [
         "7042",
         "7043",
         "نادي السيارات"
        ],
        [
         "7837",
         "7838",
         "Lady Windermere's Fan"
        ],
        [
         "9771",
         "9772",
         "The Amateur Marriage"
        ],
        [
         "9899",
         "9900",
         "Guts"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>972</td>\n",
       "      <td>Journey to the Center of the Earth (Extraordin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1739</td>\n",
       "      <td>The Bonfire of the Vanities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>3438</td>\n",
       "      <td>فلتغفري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>4264</td>\n",
       "      <td>ذاكرة الجسد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>4300</td>\n",
       "      <td>The Ladies' Room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>5931</td>\n",
       "      <td>Adam Bede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>7043</td>\n",
       "      <td>نادي السيارات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>7838</td>\n",
       "      <td>Lady Windermere's Fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>9772</td>\n",
       "      <td>The Amateur Marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>9900</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                              title\n",
       "971       972  Journey to the Center of the Earth (Extraordin...\n",
       "1738     1739                        The Bonfire of the Vanities\n",
       "3437     3438                                            فلتغفري\n",
       "4263     4264                                        ذاكرة الجسد\n",
       "4299     4300                                   The Ladies' Room\n",
       "5930     5931                                          Adam Bede\n",
       "7042     7043                                      نادي السيارات\n",
       "7837     7838                              Lady Windermere's Fan\n",
       "9771     9772                               The Amateur Marriage\n",
       "9899     9900                                               Guts"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example for user 7531\n",
    "user_id = 7531\n",
    "liked, recs = content_recommendations_for_user(\n",
    "    user_id, ratings, books,\n",
    "    cosine_sim, book_to_idx,\n",
    "    top_n = 10, threshold = 4.0\n",
    ")\n",
    "\n",
    "print(f\"User {user_id} liked these books:\")\n",
    "display(liked)\n",
    "\n",
    "print(f\"\\nTop-10 content-based recommendations for user {user_id}:\")\n",
    "display(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1fc97940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 30102 liked these books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1c60e8f0-8389-49c0-a4c8-5e65e6ffc9c3",
       "rows": [
        [
         "1",
         "2",
         "Harry Potter and the Sorcerer's Stone (Harry Potter, #1)"
        ],
        [
         "3",
         "4",
         "To Kill a Mockingbird"
        ],
        [
         "4",
         "5",
         "The Great Gatsby"
        ],
        [
         "12",
         "13",
         "1984"
        ],
        [
         "13",
         "14",
         "Animal Farm"
        ],
        [
         "15",
         "16",
         "The Girl with the Dragon Tattoo (Millennium, #1)"
        ],
        [
         "31",
         "32",
         "Of Mice and Men"
        ],
        [
         "38",
         "39",
         "A Game of Thrones (A Song of Ice and Fire, #1)"
        ],
        [
         "42",
         "43",
         "Jane Eyre"
        ],
        [
         "47",
         "48",
         "Fahrenheit 451"
        ],
        [
         "97",
         "98",
         "The Girl Who Played with Fire (Millennium, #2)"
        ],
        [
         "115",
         "116",
         "The Adventures of Tom Sawyer"
        ],
        [
         "124",
         "125",
         "Hamlet"
        ],
        [
         "139",
         "140",
         "The Girl Who Kicked the Hornet's Nest (Millennium, #3)"
        ],
        [
         "188",
         "189",
         "The Lord of the Rings (The Lord of the Rings, #1-3)"
        ],
        [
         "190",
         "191",
         "Watchmen"
        ],
        [
         "197",
         "198",
         "The Color Purple"
        ],
        [
         "374",
         "375",
         "The Call of the Wild"
        ],
        [
         "526",
         "527",
         "Living Dead in Dallas (Sookie Stackhouse, #2)"
        ],
        [
         "546",
         "547",
         "The War of the Worlds"
        ],
        [
         "557",
         "558",
         "Dead to the World (Sookie Stackhouse, #4)"
        ],
        [
         "562",
         "563",
         "Club Dead (Sookie Stackhouse, #3)"
        ],
        [
         "623",
         "624",
         "All Together Dead (Sookie Stackhouse, #7)"
        ],
        [
         "630",
         "631",
         "Dead as a Doornail (Sookie Stackhouse, #5)"
        ],
        [
         "695",
         "696",
         "The Vampire Lestat (The Vampire Chronicles, #2)"
        ],
        [
         "719",
         "720",
         "Bleach, Volume 01"
        ],
        [
         "762",
         "763",
         "The Bluest Eye"
        ],
        [
         "802",
         "803",
         "Fruits Basket, Vol. 1"
        ],
        [
         "809",
         "810",
         "Ouran High School Host Club, Vol. 1 (Ouran High School Host Club, #1)"
        ],
        [
         "816",
         "817",
         "Howl's Moving Castle (Howl's Moving Castle, #1)"
        ],
        [
         "892",
         "893",
         "Fullmetal Alchemist, Vol. 1 (Fullmetal Alchemist, #1)"
        ],
        [
         "1085",
         "1086",
         "Guilty Pleasures (Anita Blake, Vampire Hunter, #1)"
        ],
        [
         "1256",
         "1257",
         "Halfway to the Grave (Night Huntress, #1)"
        ],
        [
         "1508",
         "1509",
         "The House of Mirth"
        ],
        [
         "1588",
         "1589",
         "Everything's Eventual: 14 Dark Tales"
        ],
        [
         "1817",
         "1818",
         "One Foot in the Grave (Night Huntress, #2)"
        ],
        [
         "2142",
         "2143",
         "Kingdom Come"
        ],
        [
         "2223",
         "2224",
         "The Lunatic Cafe (Anita Blake, Vampire Hunter #4)"
        ],
        [
         "2271",
         "2272",
         "The Millennium Trilogy (Millennium Trilogy, #1-3)"
        ],
        [
         "2274",
         "2275",
         "Destined for an Early Grave (Night Huntress, #4)"
        ],
        [
         "2286",
         "2287",
         "At Grave's End (Night Huntress, #3)"
        ],
        [
         "3300",
         "3301",
         "Hana-Kimi, Vol. 1 (Hana-Kimi, #1)"
        ],
        [
         "3495",
         "3496",
         "This Side of the Grave (Night Huntress, #5)"
        ],
        [
         "3513",
         "3514",
         "First Drop of Crimson (Night Huntress World, #1)"
        ],
        [
         "3976",
         "3977",
         "D.Gray-man, Volume 01"
        ],
        [
         "4243",
         "4244",
         "Hedda Gabler"
        ],
        [
         "4815",
         "4816",
         "One Grave at a Time (Night Huntress, #6)"
        ],
        [
         "4856",
         "4857",
         "Eternal Kiss of Darkness (Night Huntress World, #2)"
        ],
        [
         "6377",
         "6378",
         "The Wallflower, Vol. 1 (The Wallflower, #1)"
        ],
        [
         "6443",
         "6444",
         "Death Note, Vol. 2: Confluence (Death Note, #2)"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 66
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Animal Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>9319</td>\n",
       "      <td>Ouran High School Host Club, Vol. 15 (Ouran Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>9457</td>\n",
       "      <td>Fruits Basket, Vol. 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>9536</td>\n",
       "      <td>Fruits Basket, Vol. 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>9673</td>\n",
       "      <td>Fruits Basket, Vol. 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>9906</td>\n",
       "      <td>Ouran High School Host Club, Vol. 4 (Ouran Hig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                              title\n",
       "1           2  Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "3           4                              To Kill a Mockingbird\n",
       "4           5                                   The Great Gatsby\n",
       "12         13                                               1984\n",
       "13         14                                        Animal Farm\n",
       "...       ...                                                ...\n",
       "9318     9319  Ouran High School Host Club, Vol. 15 (Ouran Hi...\n",
       "9456     9457                             Fruits Basket, Vol. 14\n",
       "9535     9536                             Fruits Basket, Vol. 15\n",
       "9672     9673                              Fruits Basket, Vol. 3\n",
       "9905     9906  Ouran High School Host Club, Vol. 4 (Ouran Hig...\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 content-based recommendations for user 30102:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7cad6db7-8000-40df-88f8-1c229307edfc",
       "rows": [
        [
         "971",
         "972",
         "Journey to the Center of the Earth (Extraordinary Voyages, #3)"
        ],
        [
         "3265",
         "3266",
         "NARUTO -ナルト- 巻ノ四十三"
        ],
        [
         "4414",
         "4415",
         "美少女戦士セーラームーン新装版 1 [Bishōjo Senshi Sailor Moon Shinsōban 1]"
        ],
        [
         "4929",
         "4930",
         "Pandora Hearts 1巻"
        ],
        [
         "6026",
         "6027",
         "Naruto, Vol. 11: Impassioned Efforts (Naruto, #11)"
        ],
        [
         "6140",
         "6141",
         "Harry Potter and the Order of the Phoenix (Harry Potter, #5, Part 1)"
        ],
        [
         "6618",
         "6619",
         "The Face Of Deception (Eve Duncan, #1)"
        ],
        [
         "8213",
         "8214",
         "Sin City, Vol. 3: The Big Fat Kill (Sin City, #3)"
        ],
        [
         "9769",
         "9770",
         "مخطوطة بن إسحاق: مدينة الموتى"
        ],
        [
         "9899",
         "9900",
         "Guts"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>972</td>\n",
       "      <td>Journey to the Center of the Earth (Extraordin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>3266</td>\n",
       "      <td>NARUTO -ナルト- 巻ノ四十三</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>4415</td>\n",
       "      <td>美少女戦士セーラームーン新装版 1 [Bishōjo Senshi Sailor Moon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>4930</td>\n",
       "      <td>Pandora Hearts 1巻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>6027</td>\n",
       "      <td>Naruto, Vol. 11: Impassioned Efforts (Naruto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>6141</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>6619</td>\n",
       "      <td>The Face Of Deception (Eve Duncan, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>8214</td>\n",
       "      <td>Sin City, Vol. 3: The Big Fat Kill (Sin City, #3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9769</th>\n",
       "      <td>9770</td>\n",
       "      <td>مخطوطة بن إسحاق: مدينة الموتى</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>9900</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                              title\n",
       "971       972  Journey to the Center of the Earth (Extraordin...\n",
       "3265     3266                                 NARUTO -ナルト- 巻ノ四十三\n",
       "4414     4415  美少女戦士セーラームーン新装版 1 [Bishōjo Senshi Sailor Moon ...\n",
       "4929     4930                                  Pandora Hearts 1巻\n",
       "6026     6027  Naruto, Vol. 11: Impassioned Efforts (Naruto, ...\n",
       "6140     6141  Harry Potter and the Order of the Phoenix (Har...\n",
       "6618     6619             The Face Of Deception (Eve Duncan, #1)\n",
       "8213     8214  Sin City, Vol. 3: The Big Fat Kill (Sin City, #3)\n",
       "9769     9770                      مخطوطة بن إسحاق: مدينة الموتى\n",
       "9899     9900                                               Guts"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 30102\n",
    "user_id = 30102\n",
    "liked, recs = content_recommendations_for_user(\n",
    "    user_id, ratings, books,\n",
    "    cosine_sim, book_to_idx,\n",
    "    top_n = 10, threshold = 4.0\n",
    ")\n",
    "\n",
    "print(f\"User {user_id} liked these books:\")\n",
    "display(liked)\n",
    "\n",
    "print(f\"\\nTop-10 content-based recommendations for user {user_id}:\")\n",
    "display(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365be902",
   "metadata": {},
   "source": [
    "### content-based evaluation using leave-one-out\n",
    "\n",
    "to evaluate the content-based approach using RMSE and ranking metrics,leave-one-out splitting is used: for each user, one rating is held out for testing, and the rest are used for training/profile building.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "40769d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from book_id to index\n",
    "book_to_idx = pd.Series(books.index, index = books['book_id']).to_dict()\n",
    "idx_to_book = {idx: bid for bid, idx in book_to_idx.items()}\n",
    "\n",
    "def leave_one_out(df, user_col = 'user_id', item_col = 'book_id'):\n",
    "\n",
    "    train_parts, test_parts = [], []\n",
    "\n",
    "    for uid, grp in df.groupby(user_col):\n",
    "        if len(grp) < 2:\n",
    "            train_parts.append(grp)\n",
    "        else:\n",
    "            grp_shuffled = grp.sample(frac = 1, random_state = 42)\n",
    "            test_parts.append(grp_shuffled.iloc[:1])\n",
    "            train_parts.append(grp_shuffled.iloc[1:])\n",
    "\n",
    "    train_df = pd.concat(train_parts).reset_index(drop = True)\n",
    "    test_df  = pd.concat(test_parts).reset_index(drop = True)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = leave_one_out(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "79901997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build user‑ratings dict & global mean\n",
    "user_ratings = train_df.groupby('user_id').apply(\n",
    "    lambda g: dict(zip(g['book_id'], g['rating']))\n",
    ").to_dict()\n",
    "\n",
    "GLOBAL_MEAN = train_df['rating'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2e31c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating predictor via Content Similarity\n",
    "def predict_rating(user_id, book_id, k=10):\n",
    "    if user_id not in user_ratings or book_id not in book_to_idx:\n",
    "        return GLOBAL_MEAN\n",
    "\n",
    "    idx = book_to_idx[book_id]\n",
    "    sims = list(enumerate(cosine_sim[idx]))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    num, den, count = 0.0, 0.0, 0\n",
    "    for other_idx, score in sims:\n",
    "        other_bid = idx_to_book[other_idx]\n",
    "        if other_bid in user_ratings[user_id]:\n",
    "            r = user_ratings[user_id][other_bid]\n",
    "            num += score * r\n",
    "            den += abs(score)\n",
    "            count += 1\n",
    "            if count >= k:\n",
    "                break\n",
    "\n",
    "    return (num / den) if den > 0 else GLOBAL_MEAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1e972a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rmse() missing 1 required positional argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate RMSE on the test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m preds \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: predict_rating(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rmse_value \u001b[38;5;241m=\u001b[39m \u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-based RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: rmse() missing 1 required positional argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "# Evaluate RMSE on the test set\n",
    "preds = test_df.apply(lambda row: predict_rating(row['user_id'], row['book_id']), axis=1)\n",
    "rmse_value = rmse((test_df['rating'], preds))\n",
    "print(f\"Content-based RMSE: {rmse_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top‑K Recommendations for Ranking Metrics\n",
    "def top_k_recs_for_user(user_id, K = 10):\n",
    "    if user_id not in user_ratings:\n",
    "        return []\n",
    "    agg_scores = {}\n",
    "    for bid, _ in user_ratings[user_id].items():\n",
    "        if bid not in book_to_idx:\n",
    "            continue\n",
    "        idx = book_to_idx[bid]\n",
    "        for j, score in enumerate(cosine_sim[idx]):\n",
    "            agg_scores[j] = agg_scores.get(j, 0) + score\n",
    "\n",
    "    seen = set(user_ratings[user_id])\n",
    "    candidates = [(j, s) for j, s in agg_scores.items() if idx_to_book[j] not in seen]\n",
    "    top = sorted(candidates, key=lambda x: x[1], reverse=True)[:K]\n",
    "    return [idx_to_book[j] for j, _ in top]\n",
    "\n",
    "# Prepare ground‑truth relevant items (rating ≥ 4.0)\n",
    "relevants = test_df[test_df['rating'] >= 4.0].groupby('user_id')['book_id'].apply(set).to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Evaluation Metrics\n",
    "def evaluate_ranking(K = 10):\n",
    "    precisions, recalls, hits, APs = [], [], [], []\n",
    "\n",
    "    for uid, true_set in relevants.items():\n",
    "        recs = top_k_recs_for_user(uid, K)\n",
    "        if not true_set:\n",
    "            continue\n",
    "\n",
    "        # Hit rate\n",
    "        hit = int(bool(set(recs) & true_set))\n",
    "        hits.append(hit)\n",
    "\n",
    "        # Precision & Recall\n",
    "        match_count = sum(1 for b in recs if b in true_set)\n",
    "        precisions.append(match_count / K)\n",
    "        recalls.append(match_count / len(true_set))\n",
    "\n",
    "        # Average Precision\n",
    "        num_hits, sum_prec = 0, 0.0\n",
    "        for i, b in enumerate(recs, start=1):\n",
    "            if b in true_set:\n",
    "                num_hits += 1\n",
    "                sum_prec += num_hits / i\n",
    "        APs.append(sum_prec / min(len(true_set), K))\n",
    "\n",
    "    return {\n",
    "        'HitRate@K': np.mean(hits),\n",
    "        'Precision@K': np.mean(precisions),\n",
    "        'Recall@K': np.mean(recalls),\n",
    "        'MAP@K': np.mean(APs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ranking(K = 10)\n",
    "print(\"\\nRanking Metrics:\")\n",
    "for name, val in metrics.items():\n",
    "    print(f\"{name}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "882b8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get top‑10 similar books by content\n",
    "\n",
    "def get_similar_books(book_id, K = 10):\n",
    "    if book_id not in book_to_idx:\n",
    "        print(f\"Book ID {book_id} not found in index.\")\n",
    "        return pd.DataFrame(columns=['book_id','title'])\n",
    "    \n",
    "    idx = book_to_idx[book_id]\n",
    "    \n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))   \n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)[1:K+1]\n",
    "    rec_ids = [idx_to_book[j] for j, _ in sim_scores]\n",
    "    \n",
    "    return books.loc[\n",
    "        books['book_id'].isin(rec_ids),\n",
    "        ['book_id','title']\n",
    "    ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f8cff82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target book (ID: 3398): The Ugly Duckling\n",
      "\n",
      "Top 10 books similar to 'The Ugly Duckling':\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d2cec81c-d76d-4e0d-b1ae-e5f3b53077c2",
       "rows": [
        [
         "0",
         "1120",
         "Aesop's Fables"
        ],
        [
         "1",
         "4291",
         "Alice's Adventures in Wonderland: A Pop-Up Adaptation"
        ],
        [
         "2",
         "5718",
         "Beauty and the Beast"
        ],
        [
         "3",
         "6514",
         "The Hat"
        ],
        [
         "4",
         "6526",
         "Kitten's First Full Moon"
        ],
        [
         "5",
         "6778",
         "Madeline and the Bad Hat"
        ],
        [
         "6",
         "7298",
         "Rikki-Tikki-Tavi"
        ],
        [
         "7",
         "7481",
         "When We Were Very Young (Winnie-the-Pooh, #3)"
        ],
        [
         "8",
         "8192",
         "The Giraffe and the Pelly and Me"
        ],
        [
         "9",
         "8665",
         "The Country Mouse and the City Mouse; The Fox and the Crow; The Dog and His Bone"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1120</td>\n",
       "      <td>Aesop's Fables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4291</td>\n",
       "      <td>Alice's Adventures in Wonderland: A Pop-Up Ada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5718</td>\n",
       "      <td>Beauty and the Beast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6514</td>\n",
       "      <td>The Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6526</td>\n",
       "      <td>Kitten's First Full Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6778</td>\n",
       "      <td>Madeline and the Bad Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7298</td>\n",
       "      <td>Rikki-Tikki-Tavi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7481</td>\n",
       "      <td>When We Were Very Young (Winnie-the-Pooh, #3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8192</td>\n",
       "      <td>The Giraffe and the Pelly and Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8665</td>\n",
       "      <td>The Country Mouse and the City Mouse; The Fox ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title\n",
       "0     1120                                     Aesop's Fables\n",
       "1     4291  Alice's Adventures in Wonderland: A Pop-Up Ada...\n",
       "2     5718                               Beauty and the Beast\n",
       "3     6514                                            The Hat\n",
       "4     6526                           Kitten's First Full Moon\n",
       "5     6778                           Madeline and the Bad Hat\n",
       "6     7298                                   Rikki-Tikki-Tavi\n",
       "7     7481      When We Were Very Young (Winnie-the-Pooh, #3)\n",
       "8     8192                   The Giraffe and the Pelly and Me\n",
       "9     8665  The Country Mouse and the City Mouse; The Fox ..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id = 3398   # replace with any book_id \n",
    "\n",
    "target_title = books.loc[books['book_id'] == target_id, 'title'].iloc[0]\n",
    "\n",
    "recommendations = get_similar_books(target_id, K = 10)\n",
    "\n",
    "print(f\"Target book (ID: {target_id}): {target_title}\\n\")\n",
    "print(f\"Top 10 books similar to '{target_title}':\")\n",
    "recommendations.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf7e11",
   "metadata": {},
   "source": [
    "##  Two‑Tower Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7c16ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bf5f9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ea2fb",
   "metadata": {},
   "source": [
    "### preprocess: build user history and ID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "69aca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings\n",
    "user2idx = {u: i for i, u in enumerate(ratings['user_id'].unique())}\n",
    "book2idx = {b: i for i, b in enumerate(books['book_id'].unique())}\n",
    "\n",
    "# user history: list of past rated book indices for each user\n",
    "user_hist = ratings.groupby('user_id')['book_id'].apply(list).to_dict()\n",
    "\n",
    "# convert book_ids in history to indices\n",
    "user_hist_idx = {user2idx[u]: [book2idx[b] for b in hist] for u, hist in user_hist.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee94b35",
   "metadata": {},
   "source": [
    "### dataset & dataLlader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "19eec2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerDataset(Dataset):\n",
    "    def __init__(self, ratings_df):\n",
    "        self.data = ratings_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        uid = user2idx[row['user_id']]\n",
    "        bid = book2idx[row['book_id']]\n",
    "        hist = user_hist_idx.get(uid, [])\n",
    "        rating = torch.tensor(row['rating'], dtype = torch.float)\n",
    "        return uid, torch.tensor(hist, dtype = torch.long), bid, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9581a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ratings, test_size = 0.2, random_state = 42)\n",
    "train_ds = TwoTowerDataset(train_df)\n",
    "\n",
    "test_ds  = TwoTowerDataset(test_df)\n",
    "train_loader = DataLoader(train_ds, batch_size = 256, shuffle = True, collate_fn = lambda batch: batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e95ce1",
   "metadata": {},
   "source": [
    "### model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a9c96fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_users, num_books, emb_dim = 64, hist_dim = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        # embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.book_emb = nn.Embedding(num_books, emb_dim)\n",
    "        \n",
    "        # Towers\n",
    "        # User tower: combine user ID + mean history\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, hist_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hist_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "        # Item tower: book embedding\n",
    "        self.item_mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hist_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hist_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, histories, book_ids):\n",
    "        # user ID embedding\n",
    "        u = self.user_emb(user_ids)  \n",
    "\n",
    "        # 1) turn each history list into a tensor on the right device\n",
    "        hist_tensors = [\n",
    "            torch.tensor(h, dtype = torch.long, device = device)\n",
    "            for h in histories\n",
    "        ]\n",
    "\n",
    "        # 2) pad them (batch_first) on the same device\n",
    "        padded = pad_sequence(hist_tensors, batch_first=True, padding_value = 0)  \n",
    "\n",
    "        # lookup embeddings and take mean\n",
    "        h_emb = self.book_emb(padded)     \n",
    "        h_mean = h_emb.mean(dim = 1)        \n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        # combine\n",
    "        u_concat = torch.cat([u, h_mean], dim=1)  \n",
    "        u_vec = self.user_mlp(u_concat)          \n",
    "\n",
    "        # item tower\n",
    "        i = self.book_emb(book_ids)\n",
    "        i_vec = self.item_mlp(i)  \n",
    "\n",
    "        score = (u_vec * i_vec).sum(dim=1)\n",
    "        return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e7e69b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "num_users = len(user2idx)\n",
    "num_books = len(book2idx)\n",
    "model = TwoTowerModel(num_users, num_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd1065",
   "metadata": {},
   "source": [
    "### training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6f95558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train MSE: 0.9174\n",
      "Epoch 2 — Train MSE: 0.7642\n",
      "Epoch 3 — Train MSE: 0.7451\n",
      "Epoch 4 — Train MSE: 0.7362\n",
      "Epoch 5 — Train MSE: 0.7285\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        user_ids, histories, book_ids, ratings_true = zip(*batch)\n",
    "        user_ids = torch.tensor(user_ids, device=device)\n",
    "        book_ids = torch.tensor(book_ids, device=device)\n",
    "        ratings_true = torch.stack(ratings_true).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(user_ids, histories, book_ids)\n",
    "        loss = criterion(preds, ratings_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} — Train MSE: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c1777",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2bf276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute item embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_book_ids = torch.arange(num_books, device = device)\n",
    "    item_embs = model.item_mlp(model.book_emb(all_book_ids)) \n",
    "\n",
    "# top-10 for a given user\n",
    "def recommend_user(user_id, K = 10):\n",
    "    uid = user2idx[user_id]\n",
    "\n",
    "    # get user vector\n",
    "    u_vec = model.user_mlp(torch.cat([\n",
    "        model.user_emb(torch.tensor([uid], device=device)),\n",
    "        model.book_emb(torch.tensor(user_hist_idx[uid], device=device)).mean(dim=0, keepdim=True)\n",
    "    ], dim=1))  \n",
    "\n",
    "    # compute scores\n",
    "    scores = torch.matmul(item_embs, u_vec.squeeze())\n",
    "    topk = torch.topk(scores, K).indices.cpu().numpy()\n",
    "    return books.iloc[topk][['book_id','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "11aeaf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id                                              title\n",
      "5206     5207  The Days Are Just Packed: A Calvin and Hobbes ...\n",
      "8945     8946                                          The Divan\n",
      "9075     9076    Preach My Gospel: A Guide To Missionary Service\n",
      "1787     1788       The Calvin and Hobbes Tenth Anniversary Book\n",
      "8547     8548                                 This is Not My Hat\n",
      "8662     8663                 Locke & Key, Vol. 6: Alpha & Omega\n",
      "4482     4483  It's a Magical World: A Calvin and Hobbes Coll...\n",
      "3627     3628                     The Complete Calvin and Hobbes\n",
      "779       780                                  Calvin and Hobbes\n",
      "6750     6751  The Declaration of Independence and The Consti...\n"
     ]
    }
   ],
   "source": [
    "print(recommend_user(ratings['user_id'].iloc[0], K = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da539a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd66f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ccebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b99a07",
   "metadata": {},
   "source": [
    "**Overall Goal:**\n",
    "\n",
    "The primary goal is to compare different recommendation algorithms based on their ability to predict user ratings (accuracy) and suggest relevant books (ranking quality). It starts with simple baselines and progresses to more complex collaborative filtering, content-based, and deep learning methods.\n",
    "\n",
    "**1. Initial Setup & Data Loading**\n",
    "\n",
    "* **Load Data:**\n",
    "    * `ratings = pd.read_csv('data/FINAL-RATINGS.csv')`: Loads user ratings data (likely containing `user_id`, `book_id`, `rating`).\n",
    "    * `books = pd.read_csv('data/FINAL-BOOKS-WITH-TAGS.csv')`: Loads book metadata (likely containing `book_id`, `title`, `description`, `tags`, etc.).\n",
    "    * `ratings.shape, books.shape`: Prints the dimensions (rows, columns) of the loaded DataFrames to get an idea of the data size.\n",
    "\n",
    "**2. Baseline Model: Popularity-Based**\n",
    "\n",
    "* **Purpose:** To establish a very simple benchmark. This model recommends the same most popular books to *every* user, regardless of their individual preferences.\n",
    "* **Metrics Definition:** Explains the ranking metrics used throughout the notebook:\n",
    "    * `Precision@K`: Out of the K books recommended, what fraction did the user actually rate highly (often defined as rating >= threshold like 4.0) in the hidden test set?\n",
    "    * `Recall@K`: Out of all the books the user rated highly in the hidden test set, what fraction were captured within the top K recommendations?\n",
    "    * `Hit Rate@K`: Did *at least one* of the user's highly-rated test set books appear in the top K recommendations? (Binary: 1 if yes, 0 if no, then averaged over users).\n",
    "* **Train/Test Split (Standard):** `train_test_split(ratings, ...)` splits the `ratings` data (80% train, 20% test) so the model's performance can be evaluated on unseen data. `random_state=42` ensures reproducibility.\n",
    "* **Calculate Popularity:**\n",
    "    * `train_df['book_id'].value_counts()`: Counts how many times each `book_id` appears in the *training* data. This count represents popularity.\n",
    "    * The result is stored in the `popularity` DataFrame.\n",
    "* **Get Top N Popular:**\n",
    "    * `N = 10`: Sets the number of recommendations to generate (K=10).\n",
    "    * `popularity.head(N)`: Selects the N most frequent (popular) books.\n",
    "    * `.merge(...)`: Joins this with the `books` DataFrame to get the titles and average ratings for these popular books.\n",
    "    * `print(...)`, `top_popular.head(N)`: Displays the top N popular books.\n",
    "* **Evaluate Popularity Baseline:**\n",
    "    * **RMSE:**\n",
    "        * `book_means`: Calculates the average rating for each book based *only* on the training data.\n",
    "        * `global_mean`: Calculates the overall average rating across *all* ratings in the training data.\n",
    "        * `test_preds`: For each rating in the test set, it predicts the rating as the book's average rating (from `book_means`). If the book wasn't in the training set (no average rating available), it predicts the `global_mean`.\n",
    "        * `rmse_baseline`: Calculates RMSE between the predicted ratings and the actual ratings in the test set.\n",
    "    * **Precision@N, Recall@N, HitRate@N:**\n",
    "        * `truth`: Creates a dictionary where keys are `user_id`s and values are *sets* of `book_id`s that the user rated in the *test* set. This is the \"ground truth\" for ranking evaluation.\n",
    "        * Loop: Iterates through each user and their actual test set books (`actual`).\n",
    "        * `hit_count`: Calculates how many books from the `top_popular` list are *also* present in the user's `actual` test set books.\n",
    "        * Metrics Calculation: Calculates Precision (`hit_count / N`), Recall (`hit_count / len(actual)`), and Hit Rate (`int(hit_count > 0)`) for *each user*.\n",
    "        * `np.mean(...)`: Averages these metrics across all users in the test set.\n",
    "    * `print(...)`: Displays the calculated baseline metrics.\n",
    "\n",
    "**3. Baseline Model: Weighted Rating (IMDb Style)**\n",
    "\n",
    "* **Purpose:** A slightly more sophisticated baseline. It still recommends popular items globally, but it uses a weighted rating formula (like IMDb's) that balances a book's average rating with the number of ratings it has received. This prevents books with few high ratings from dominating purely popular books with many moderate ratings.\n",
    "* **RMSE Function:** Defines a helper function `rmse`.\n",
    "* **Calculate Stats:** `pop_stats` DataFrame calculates the average rating (`avg_rating`) and rating count (`count_ratings`) for each book from the training data.\n",
    "* **IMDb Formula Implementation:**\n",
    "    * `m`: Calculates a minimum vote threshold (here, the 90th percentile of rating counts). Books with fewer ratings than `m` will have their scores adjusted more significantly towards the global average.\n",
    "    * `C`: The prior belief, set to the `global_mean` rating from the training set.\n",
    "    * `weighted_rating`: Applies the formula: `(v/(v+m))*R + (m/(v+m))*C`, where `v` is count, `R` is average rating.\n",
    "* **Top-N Weighted:** Selects the top N books based on this calculated `weighted_rating`.\n",
    "* **Evaluation (RMSE, Precision, Recall, HitRate):**\n",
    "    * Calculates RMSE using the `weighted_rating` as the prediction (falling back to `C` if a book isn't found).\n",
    "    * Calculates Precision, Recall, and HitRate similarly to the first baseline, but compares against the `top_weighted_ids` list.\n",
    "* **Print Results:** Displays the weighted-rating baseline metrics.\n",
    "* **Comparative Metrics:** Prints a formatted table comparing the simple popularity and weighted rating baselines side-by-side.\n",
    "\n",
    "**4. Memory-Based Collaborative Filtering (CF) using KNN**\n",
    "\n",
    "* **Purpose:** Moves beyond global recommendations to personalized ones based on user/item similarity.\n",
    "    * **User-User CF:** Recommends items that *similar users* liked. Similarity is based on rating patterns.\n",
    "    * **Item-Item CF:** Recommends items that are *similar* to items the user *already liked*. Similarity is based on users who rated both items similarly.\n",
    "* **Prepare Surprise Data:**\n",
    "    * `Reader`: Defines the rating scale (1 to 5).\n",
    "    * `Dataset.load_from_df`: Loads the `ratings` DataFrame (selecting only relevant columns) into Surprise's internal data format.\n",
    "    * `surprise_train_test_split`: Splits the Surprise `data` object into `trainset` and `testset`.\n",
    "* **`precision_recall_hit_at_k` Helper Function:**\n",
    "    * This function is crucial for evaluating ranking metrics with Surprise models.\n",
    "    * It takes Surprise's prediction output (`preds`, which is a list of tuples: `uid, iid, true_rating, estimated_rating, details`).\n",
    "    * Groups predictions by user (`user_pred_true`).\n",
    "    * For each user:\n",
    "        * Sorts their predicted items by the `estimated_rating` in descending order.\n",
    "        * Selects the `top_k` items.\n",
    "        * Calculates `n_rel`: Total number of *actually relevant* items for this user in the test set (true rating >= threshold).\n",
    "        * Calculates `n_rec`: Number of *recommended relevant* items in the `top_k`.\n",
    "        * Calculates and stores Precision@K, Recall@K, and HitRate@K for that user.\n",
    "    * Returns the average metrics across all users.\n",
    "* **Results List:** `results = []` initializes a list to store evaluation metrics for different models.\n",
    "* **User-User CF (`algo_uu`):**\n",
    "    * `KNNBasic`: Instantiates the K-Nearest Neighbors algorithm from Surprise.\n",
    "    * `sim_options`: Specifies similarity calculation (cosine similarity, `user_based=True`).\n",
    "    * `k=30`: Use 30 nearest neighbors.\n",
    "    * `verbose=False`: Suppresses training output.\n",
    "    * `algo_uu.fit(trainset)`: Trains the model on the training data.\n",
    "    * `pred_uu = algo_uu.test(testset)`: Makes predictions on the test set.\n",
    "    * `rmse_uu = accuracy.rmse(...)`: Calculates RMSE using Surprise's accuracy module.\n",
    "    * `m_uu = precision_recall_hit_at_k(...)`: Calculates ranking metrics using the helper function.\n",
    "    * Appends the results (model name, RMSE, P@10, R@10, H@10) to the `results` list.\n",
    "* **Item-Item CF (`algo_ii`):**\n",
    "    * Same process as User-User, but with `user_based=False` in `sim_options`.\n",
    "* **Display KNN Results:** Creates a Pandas DataFrame `df_knn` from the `results` list and displays the comparison.\n",
    "\n",
    "**5. Model-Based Collaborative Filtering using SVD**\n",
    "\n",
    "* **Purpose:** Uses Matrix Factorization (specifically Singular Value Decomposition - SVD) to learn latent features (embeddings) for users and items. It predicts ratings by taking the dot product of user and item latent vectors. Often performs better than KNN, especially on sparse data.\n",
    "* **Basic SVD (`algo_svd`):**\n",
    "    * Instantiates a basic `SVD` model from Surprise.\n",
    "    * Fits, tests, calculates RMSE and ranking metrics, and appends to `results`.\n",
    "* **SVD with Bias & Parameters (`algo_svd` - overwritten):**\n",
    "    * Instantiates `SVD` again, but with common tuning parameters:\n",
    "        * `n_factors=50`: Number of latent dimensions to learn.\n",
    "        * `biased=True`: Includes baseline estimates (user/item biases) in the prediction, often improving accuracy.\n",
    "        * `reg_all=0.02`: Regularization term to prevent overfitting.\n",
    "        * `lr_all=0.005`: Learning rate for the optimization algorithm (stochastic gradient descent).\n",
    "    * Fits, tests, calculates metrics (`pred_svd_bias`), and appends results. *Note: This overwrites the previous `algo_svd` variable, but the results from the basic SVD were already stored.*\n",
    "* **Display SVD Results:** Creates `df_svd` (using the updated `results` list containing UU, II, SVD, SVD-Bias results) and displays it.\n",
    "\n",
    "**6. Displaying Recommendations**\n",
    "\n",
    "* **Purpose:** To show concrete examples of the recommendations generated by the different trained models for specific users.\n",
    "* **`get_top_n` Function:**\n",
    "    * Takes the prediction output from a Surprise model.\n",
    "    * Groups predictions by user.\n",
    "    * For each user, sorts their predicted items by estimated rating.\n",
    "    * Returns a dictionary mapping `user_id` to a list of their top `n` recommended (`book_id`, `estimated_rating`) tuples.\n",
    "* **Generate Top-10 Lists:** Calls `get_top_n` for each of the four CF models trained (User-User, Item-Item, SVD, SVD-Bias).\n",
    "* **Prepare for Display:**\n",
    "    * `models`: A dictionary to easily access the top-10 lists for each model.\n",
    "    * `user_ids`: A list of specific users to generate recommendations for.\n",
    "* **Loop and Display:**\n",
    "    * Iterates through the selected `user_ids`.\n",
    "    * For each user, it iterates through the `models`.\n",
    "    * Retrieves the top-10 recommended `book_id`s for the current model and user.\n",
    "    * Looks up the corresponding book `title`s from the `books` DataFrame.\n",
    "    * Stores these titles in a dictionary `data`.\n",
    "    * Creates a DataFrame `df_side` where columns are model names and rows are the recommended titles (rank 1 to 10).\n",
    "    * Uses `display(df_side)` (specific to Jupyter environments) to show the recommendations side-by-side for that user.\n",
    "\n",
    "**7. Markdown Summary Cells**\n",
    "\n",
    "* These cells (`## Model Comparison`, `## 1. RMSE`, etc.) use Markdown formatting to:\n",
    "    * Present the final evaluation metrics (RMSE, Precision@10, Recall@10, Hit@10) from the `df_svd` DataFrame in clear tables.\n",
    "    * Reiterate the interpretation of RMSE (lower is better).\n",
    "    * Show Top-5 metrics (requires recalculating or adjusting the `precision_recall_hit_at_k` function for K=5, which isn't explicitly shown here but the results are presented).\n",
    "    * Explain *why* SVD often performs well (latent factors, regularization, handling sparsity).\n",
    "    * Show a sample Top-5 recommendation list for one user (taken from one of the models, likely User-User based on the heading).\n",
    "    * Provide a final summary comparing models and recommending SVD for accuracy/ranking and Item-Item for interpretability.\n",
    "\n",
    "**8. Content-Based Filtering**\n",
    "\n",
    "* **Purpose:** Recommends items based on their textual content (description, tags) similarity to items a user liked previously. It doesn't rely on other users' behavior.\n",
    "* **Content Field:** Creates a combined 'content' column from book descriptions and tags.\n",
    "* **Text Cleaning:**\n",
    "    * Downloads `stopwords` from `nltk`.\n",
    "    * Defines `clean_text` function: converts to lowercase, removes punctuation/non-alphanumeric characters (except spaces), splits into tokens, removes common English stopwords.\n",
    "    * Applies cleaning to the 'content' column -> 'content_clean'.\n",
    "* **TF-IDF Vectorization:**\n",
    "    * `TfidfVectorizer`: Initializes the vectorizer. TF-IDF (Term Frequency-Inverse Document Frequency) converts text into numerical vectors, giving higher weight to words that are frequent in a specific document but rare across all documents.\n",
    "    * `tfidf.fit_transform()`: Learns the vocabulary and IDF weights from 'content_clean' and transforms the text into a sparse TF-IDF matrix (`tfidf_matrix`).\n",
    "* **Cosine Similarity:**\n",
    "    * `linear_kernel(tfidf_matrix, tfidf_matrix)`: Efficiently computes the cosine similarity between all pairs of book TF-IDF vectors. The result `cosine_sim` is a matrix where `cosine_sim[i][j]` is the content similarity between book `i` and book `j`.\n",
    "    * `book_idx`, `book_to_idx`, `idx_to_book`: Creates mappings between `book_id` and the row index in the `books` DataFrame / `cosine_sim` matrix.\n",
    "* **Generating Recommendations (Example User):**\n",
    "    * Picks a `sample_user`.\n",
    "    * Finds `liked_book_ids` (rated >= 4.0) for that user from the *full* `ratings` dataset.\n",
    "    * `agg_scores`: Calculates aggregate similarity scores. It iterates through the user's liked books. For each liked book, it adds its similarity scores (from `cosine_sim`) to all *other* books into the `agg_scores` dictionary. Books similar to multiple liked books get higher scores.\n",
    "    * Removes books the user has already seen (`liked_book_ids`) from `agg_scores`.\n",
    "    * Sorts the remaining books by aggregated score and gets the top `N` indices.\n",
    "    * Looks up the titles and displays the recommendations.\n",
    "* **Content-Based Evaluation (Leave-One-Out):**\n",
    "    * **Purpose:** To evaluate the content-based approach using RMSE and ranking metrics, similar to the CF models. Leave-One-Out (LOO) splitting is used: for each user, one rating is held out for testing, and the rest are used for training/profile building.\n",
    "    * **LOO Split Function:** Defines `leave_one_out` to perform this split.\n",
    "    * Applies LOO to the `ratings` data.\n",
    "    * `user_ratings`: Creates a dictionary mapping users to their *training* ratings.\n",
    "    * `GLOBAL_MEAN`: Calculated from the *training* data.\n",
    "    * **`predict_rating` Function:**\n",
    "        * Predicts the rating for a *test* user-item pair.\n",
    "        * Finds the `k` most similar items (based on `cosine_sim`) to the target item *that the user has rated in their training history*.\n",
    "        * Predicts the rating as a weighted average of the ratings given to those similar items, where the weight is the cosine similarity score. Falls back to `GLOBAL_MEAN` if needed.\n",
    "    * **RMSE Evaluation:** Applies `predict_rating` to the LOO test set and calculates RMSE.\n",
    "    * **`top_k_recs_for_user` Function (Ranking):** Generates top-K recommendations for a user based on aggregating content similarity scores from their *training* history (similar to the example).\n",
    "    * `relevants`: Defines the ground truth for ranking – items in the *test* set rated >= 4.0.\n",
    "    * **`evaluate_ranking` Function:** Calculates HitRate@K, Precision@K, Recall@K, and MAP@K (Mean Average Precision - considers the rank of correct items) using the LOO test setup.\n",
    "    * Calls `evaluate_ranking` and prints the results.\n",
    "* **`get_similar_books` Function (Item-to-Item Content Similarity):**\n",
    "    * A utility function to find the K most similar books to a *given* book based purely on content (`cosine_sim`).\n",
    "    * Used for demonstrating item-based content similarity.\n",
    "\n",
    "**9. Two-Tower Recommendation System (Deep Learning)**\n",
    "\n",
    "* **Purpose:** Implements a more advanced deep learning model. It learns separate representations (embeddings) for users and items in two parallel \"towers\" (neural networks) and predicts compatibility using their outputs. This is common for large-scale industrial systems.\n",
    "* **Imports:** `torch` and related modules for deep learning.\n",
    "* **Preprocessing:**\n",
    "    * `user2idx`, `book2idx`: Creates integer mappings for user/book IDs, essential for embedding layers in neural networks.\n",
    "    * `user_hist_idx`: Creates a dictionary mapping user *index* to a list of book *indices* they have rated. This interaction history is used as input to the user tower.\n",
    "* **Dataset & DataLoader:**\n",
    "    * `TwoTowerDataset`: A PyTorch `Dataset` to load data efficiently. `__getitem__` returns the user index, their history (as a list of book indices), the target book index, and the rating.\n",
    "    * Standard `train_test_split` on the original `ratings` DataFrame.\n",
    "    * `DataLoader`: Batches the data. `collate_fn=lambda batch: batch` is used here, meaning padding of histories likely happens inside the model's `forward` method.\n",
    "* **Model Definition (`TwoTowerModel`):**\n",
    "    * Inherits from `nn.Module`.\n",
    "    * `__init__`:\n",
    "        * `nn.Embedding`: Layers to learn dense vector representations (embeddings) for users and books.\n",
    "        * `user_mlp`: A Multi-Layer Perceptron (MLP) for the user tower. It takes the concatenation of the user's ID embedding and the *mean* of the embeddings of books in their history.\n",
    "        * `item_mlp`: An MLP for the item tower, taking the target book's embedding.\n",
    "    * `forward`: Defines how data flows through the model:\n",
    "        * Gets user ID embedding.\n",
    "        * Pads histories within the batch to the same length.\n",
    "        * Gets embeddings for books in the history.\n",
    "        * Calculates the *mean* embedding of the history sequence (a simple way to summarize history).\n",
    "        * Concatenates user ID embedding and mean history embedding.\n",
    "        * Passes the combined vector through the `user_mlp` -> `u_vec`.\n",
    "        * Gets the target book embedding and passes it through the `item_mlp` -> `i_vec`.\n",
    "        * Calculates the dot product of `u_vec` and `i_vec` as the predicted score/rating.\n",
    "* **Model Instantiation:** Creates the model instance.\n",
    "* **Training Loop:**\n",
    "    * Sets up device (GPU/CPU), optimizer (`Adam`), and loss function (`MSELoss` for rating prediction).\n",
    "    * Standard PyTorch training loop: iterates epochs, gets batches, moves data to device, forward pass, calculates loss, backpropagation, optimizer step. Prints training loss per epoch.\n",
    "* **Inference:**\n",
    "    * `model.eval()`: Sets the model to evaluation mode (disables dropout, etc.).\n",
    "    * **Precompute Item Embeddings:** Calculates and stores the embeddings for *all* books using the trained item tower (`item_embs`). This is efficient for generating recommendations later.\n",
    "    * **`recommend_user` Function:**\n",
    "        * Takes a `user_id`.\n",
    "        * Calculates the user's final embedding (`u_vec`) using the trained user tower (user ID emb + mean history emb).\n",
    "        * Calculates the dot product between this `u_vec` and *all* precomputed `item_embs`.\n",
    "        * Uses `torch.topk` to find the items (books) with the highest scores.\n",
    "        * Maps the resulting indices back to book IDs/titles.\n",
    "    * **Example Usage:** Calls `recommend_user` for specific users to demonstrate recommendation generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49500d96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3690839f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
